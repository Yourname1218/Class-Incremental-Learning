# Stacking Ensemble 方法流程圖

## 核心Stacking方法流程

```mermaid
flowchart TD
    A[開始] --> B[載入多個基礎模型<br/>搜尋 task_XX_200_model.pkl<br/>預期載入11個模型 Task 0-10]
    B --> C{執行模式}
    
    C -->|訓練模式| D[準備訓練數據<br/>使用驗證集數據<br/>包含所有1000個類別]
    C -->|評估模式| E[載入已訓練元模型<br/>stacking_meta_model.pkl]
    
    %% 訓練模式分支
    D --> F[收集基礎模型預測<br/>每個模型輸出1000維logits<br/>形狀: batch_size x 1000]
    F --> G[分割數據集<br/>70%訓練集 vs 30%測試集<br/>再分割20%作為驗證集]
    G --> H[創建元模型 StackingMetaModel<br/>權重矩陣: 11 x 1000<br/>學習每個模型對每類的貢獻]
    H --> I[訓練元模型 30 epochs<br/>學習率: 0.001<br/>ReduceLROnPlateau調度器<br/>學習如何最佳組合預測]
    I --> J[保存訓練好的元模型<br/>保存最佳驗證準確率模型]
    J --> K[使用元模型進行最終預測<br/>線性加權組合所有模型預測]
    K --> L[輸出結果<br/>整體/前500類/後500類準確率]
    
    %% 評估模式分支
    E --> M[準備測試數據<br/>使用medicine_picture/valid]
    M --> N[收集基礎模型預測<br/>批次大小: 32]
    N --> O[使用元模型組合預測<br/>weighted_sum = predictions × weights]
    O --> P[評估性能<br/>計算各類別準確率]
    P --> L
```

## Stacking方法核心概念

```mermaid
flowchart LR
    A[Task 0 模型<br/>負責前500類<br/>基礎模型 強度高] --> D[元模型 StackingMetaModel<br/>權重矩陣 11×1000<br/>可學習參數]
    B[Task 1-10 模型<br/>各負責50類範圍<br/>增量學習模型] --> D
    C[11個模型總計<br/>覆蓋全部1000類] --> D
    
    D --> E[智能權重分配<br/>動態學習最佳組合]
    E --> F[最終預測結果<br/>提升整體準確率]
    
    G[權重初始化策略<br/>程式碼設定] --> H[Task 0: 前500類<br/>初始權重 = 1.5]
    H --> I[Task 1-10: 各自範圍<br/>初始權重 = 3.0<br/>更高權重突出專業性]
```

## 元模型訓練過程

```mermaid
flowchart TD
    A[所有基礎模型對訓練集的預測<br/>收集11個模型的預測結果] --> B[堆疊預測張量<br/>形狀: batch_size x 11 x 1000<br/>移到CPU節省GPU記憶體]
    B --> C[元模型權重矩陣<br/>形狀: 11 x 1000<br/>每個模型對每類的權重]
    C --> D[線性加權組合<br/>weighted_preds = predictions × weights<br/>求和維度=1 模型維度]
    D --> E[與真實標籤計算損失<br/>CrossEntropyLoss<br/>批次大小: 32]
    E --> F[反向傳播更新權重<br/>Adam優化器 lr=0.001<br/>ReduceLROnPlateau factor=0.5 patience=5]
    F --> G{訓練完成?<br/>30 epochs 或提早停止}
    G -->|否| C
    G -->|是| H[保存最佳元模型<br/>基於最佳驗證準確率]
```

## 預測階段流程

```mermaid
flowchart TD
    A[測試圖像<br/>224×224 RGB<br/>CenterCrop + Normalize] --> B[Task 0 模型預測<br/>前500類專家<br/>輸出1000維logits]
    A --> C[Task 1 模型預測<br/>類別500-549專家<br/>輸出1000維logits]
    A --> D[Task 2-10 模型預測<br/>各50類專家<br/>每個輸出1000維logits]
    A --> E[所有11個模型並行<br/>批次處理提升效率]
    
    B --> F[堆疊所有預測<br/>torch.stack batch x 11 x 1000]
    C --> F
    D --> F
    E --> F
    
    F --> G[元模型加權組合<br/>predictions × weights sum dim=1<br/>輸出: batch x 1000]
    G --> H[最終分類結果<br/>torch.max 取最大值索引<br/>計算準確率]
```

## 核心優勢與量化指標

### 1. 智能權重分配策略

```mermaid
flowchart LR
    A[前500類 基礎類別<br/>Task 0 專精領域<br/>覆蓋率: 50%] --> B[Task 0 模型<br/>初始權重 = 1.5<br/>相對重要性適中]
    C[類別 500-549<br/>Task 1 專精範圍<br/>50個類別] --> D[Task 1 模型<br/>初始權重 = 3.0<br/>專業性更強]
    E[類別 550-599<br/>Task 2 專精範圍<br/>50個類別] --> F[Task 2 模型<br/>初始權重 = 3.0<br/>專業性更強]
    G[其他類別範圍<br/>Task 3-10<br/>每個50類] --> H[對應Task模型<br/>初始權重 = 3.0<br/>各自專業領域]
```

### 2. 兩階段學習流程

```mermaid
flowchart LR
    A[階段1: 基礎模型訓練<br/>每個Task學習特定類別<br/>201 epochs 分類器<br/>1001 epochs GAN] --> B[各Task模型專精化<br/>Task 0: 前500類<br/>Task 1-10: 各50類]
    B --> C[階段2: 元模型訓練<br/>學習組合策略<br/>30 epochs<br/>70%訓練 20%驗證 10%測試] --> D[最佳組合策略<br/>自適應權重分配<br/>提升整體準確率]
```

## 方法特點與技術細節

**多模型集成**:
- 11個基礎模型 (Task 0-10)
- 總計1000個類別覆蓋
- 並行推理提升效率

**自適應權重學習**: 
- 可訓練權重矩陣 [11×1000]
- 初始化策略考慮模型專精度
- 動態學習最佳組合比例

**知識保留機制**: 
- Task 0 模型保留基礎知識
- 元模型學習平衡舊新知識
- 有效緩解災難性遺忘

**性能提升策略**: 
- 批次大小32優化記憶體使用
- 學習率調度器防止過擬合
- 驗證集提早停止機制

## 輸出結果分析與評估指標

**整體準確率**: 
- 所有1000類的平均準確率
- 目標: 超越51.21% (單一最佳模型)

**前500類準確率**: 
- 基礎類別的知識保留效果
- 評估災難性遺忘程度

**後500類準確率**: 
- 新學習類別的掌握程度
- 評估增量學習效果

**類別級別分析**: 
- 每個類別的詳細表現
- 可視化柱狀圖 class_accuracies.png
- 詳細報告 results.txt

## 核心數值參數總結

| 參數項目 | 數值 | 說明 |
|---------|------|------|
| 基礎模型數量 | 11個 | Task 0-10 |
| 總類別數 | 1000 | 完整覆蓋 |
| Task 0 類別 | 500 | 基礎類別 |
| 其他Task類別 | 50/每個 | 增量類別 |
| 元模型訓練epochs | 30 | 適中避免過擬合 |
| 學習率 | 0.001 | Adam優化器 |
| 批次大小 | 32 | 記憶體優化 |
| Task 0 初始權重 | 1.5 | 基礎重要性 |
| 其他Task初始權重 | 3.0 | 強調專業性 |
| 數據分割比例 | 70:20:10 | 訓練:驗證:測試 |